{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99867a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/b23_chiranjeevi/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b26981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reproducibility helpers\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9db6e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTAG(188)\n",
      "Num graphs: 188\n",
      "Num node features: 7\n",
      "Num classes: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load MUTAG\n",
    "\n",
    "dataset = TUDataset(\n",
    "    root=\"/data/b23_chiranjeevi/GIN_MUTAG/data/TUDataset\",\n",
    "    name=\"MUTAG\"\n",
    ")\n",
    "\n",
    "\n",
    "if dataset.num_node_features == 0:\n",
    "    raise ValueError(\"Dataset has no node features \")\n",
    "\n",
    "# Shuffle and split (80/10/10)\n",
    "dataset = dataset.shuffle()\n",
    "n = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "train_ds = dataset[:n_train]\n",
    "val_ds = dataset[n_train:n_train + n_val]\n",
    "test_ds = dataset[n_train + n_val:]\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "print(dataset)\n",
    "print(\"Num graphs:\", len(dataset))\n",
    "print(\"Num node features:\", dataset.num_node_features)\n",
    "print(\"Num classes:\", dataset.num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIN model\n",
    "\n",
    "class GIN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, out_dim: int, num_layers: int = 3, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        assert num_layers >= 2, \"Use at least 2 layers for GIN.\"\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        # First GIN layer\n",
    "        mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "        self.convs.append(GINConv(mlp))\n",
    "        self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # Hidden GIN layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "            )\n",
    "            self.convs.append(GINConv(mlp))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node updates\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = conv(x, edge_index)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Graph pooling (graph-level embedding)\n",
    "        g = global_add_pool(x, batch)\n",
    "\n",
    "        # Classifier\n",
    "        out = self.classifier(g)\n",
    "        return out\n",
    "\n",
    "model = GIN(\n",
    "    in_dim=dataset.num_node_features,\n",
    "    hidden_dim=64,\n",
    "    out_dim=dataset.num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.5,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d247a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Eval loops\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader: DataLoader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_sum = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x.float(), data.edge_index, data.batch)\n",
    "\n",
    "        # MUTAG labels are shape [batch_size] or [batch_size, 1] depending on dataset formatting\n",
    "        y = data.y.view(-1).long()\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        pred = logits.argmax(dim=-1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += y.numel()\n",
    "        loss_sum += float(loss.item()) * y.numel()\n",
    "\n",
    "    return loss_sum / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "def train_one_epoch(loader: DataLoader):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(data.x.float(), data.edge_index, data.batch)\n",
    "        y = data.y.view(-1).long()\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += y.numel()\n",
    "        loss_sum += float(loss.item()) * y.numel()\n",
    "\n",
    "    return loss_sum / max(total, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1d4100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=2.1231 | val_loss=0.9108 | val_acc=0.5000\n",
      "Epoch 010 | train_loss=0.5635 | val_loss=0.4107 | val_acc=0.7222\n",
      "Epoch 020 | train_loss=0.3513 | val_loss=0.4434 | val_acc=0.8889\n",
      "Epoch 030 | train_loss=0.3616 | val_loss=0.4631 | val_acc=0.8333\n",
      "Epoch 040 | train_loss=0.3742 | val_loss=0.4431 | val_acc=0.8333\n",
      "Epoch 050 | train_loss=0.3726 | val_loss=0.4302 | val_acc=0.8333\n",
      "Epoch 060 | train_loss=0.3332 | val_loss=0.5142 | val_acc=0.7778\n",
      "Epoch 070 | train_loss=0.3015 | val_loss=0.4217 | val_acc=0.8889\n",
      "Epoch 080 | train_loss=0.3215 | val_loss=0.4977 | val_acc=0.6667\n",
      "Epoch 090 | train_loss=0.3656 | val_loss=0.4559 | val_acc=0.7222\n",
      "Epoch 100 | train_loss=0.2955 | val_loss=0.5220 | val_acc=0.8889\n",
      "\n",
      "Best val_acc=0.9444\n",
      "Test: loss=0.4062 | acc=0.8000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_one_epoch(train_loader)\n",
    "    val_loss, val_acc = evaluate(val_loader)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.4f}\")\n",
    "\n",
    "# Load best model \n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "test_loss, test_acc = evaluate(test_loader)\n",
    "print(f\"\\nBest val_acc={best_val_acc:.4f}\")\n",
    "print(f\"Test: loss={test_loss:.4f} | acc={test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5bec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
